# -*- coding: utf-8 -*-
"""Wordle_RL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DYsmYU2xYr_vbks_f_I2_-tj8as6RQ0K
"""

import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Wordle game class
class WordleGame:
    def __init__(self, target_word):
        self.target_word = target_word.lower()
        self.max_attempts = 6

    def get_feedback(self, guess):
        feedback = [''] * 5
        target_letters = list(self.target_word)
        guess_letters = list(guess)

        # First pass: Correct letters in correct position
        for i in range(5):
            if guess_letters[i] == target_letters[i]:
                feedback[i] = 'G'  # Green for correct letter and position
                target_letters[i] = None
                guess_letters[i] = None

        # Second pass: Correct letters in wrong position
        for i in range(5):
            if guess_letters[i] is not None and guess_letters[i] in target_letters:
                feedback[i] = 'Y'  # Yellow for correct letter, wrong position
                target_letters[target_letters.index(guess_letters[i])] = None

        # Mark letters that are not in the target word
        for i in range(5):
            if feedback[i] == '':
                feedback[i] = 'X'  # Gray for incorrect letter

        return ''.join(feedback)

# Q-learning agent class
class QLearningAgent:
    def __init__(self, word_list):
        self.q_table = {}
        self.learning_rate = 0.1
        self.discount_factor = 0.9
        self.epsilon = 0.1  # Exploration probability
        self.word_list = word_list

    def get_action(self, state):
        if state not in self.q_table:
            self.q_table[state] = {word: 0 for word in self.word_list}

        if random.uniform(0, 1) < self.epsilon:
            return random.choice(self.word_list)
        else:
            return max(self.q_table[state], key=self.q_table[state].get)

    def update_q_value(self, state, action, reward):
        if state not in self.q_table:
            self.q_table[state] = {word: 0 for word in self.word_list}

        best_next_action = max(self.q_table[state], key=self.q_table[state].get)
        td_target = reward + self.discount_factor * self.q_table[state][best_next_action]
        td_error = td_target - self.q_table[state][action]
        self.q_table[state][action] += self.learning_rate * td_error

# Visualization functions
def plot_feedback_accuracy(attempts_over_episodes):
    plt.figure(figsize=(10, 5))
    plt.plot(attempts_over_episodes, marker='o', color='b', label="Attempts")
    plt.xlabel("Episode")
    plt.ylabel("Attempts Taken")
    plt.title("Feedback Accuracy over Episodes (Attempts to Guess Correctly)")
    plt.legend()
    plt.show()

def plot_q_values_heatmap(q_table):
    q_values_df = pd.DataFrame.from_dict(q_table, orient='index')
    plt.figure(figsize=(12, 8))
    sns.heatmap(q_values_df.fillna(0), annot=True, cmap="YlGnBu", fmt=".2f", cbar_kws={'label': 'Q-value'})
    plt.xlabel("Guesses")
    plt.ylabel("Feedback States")
    plt.title("Q-Value Heatmap for State-Action Pairs")
    plt.show()

def main():
    word_list = ["apple", "bread", "candy", "grape", "lemon", "mango", "peach", "plumb", "berry", "melon"]
    target_word = random.choice(word_list)
    game = WordleGame(target_word)
    agent = QLearningAgent(word_list)
    attempts_over_episodes = []

    for episode in range(1, 101):  # Number of training episodes
        state = ''
        attempts = 0
        print(f"\nEpisode {episode}: Target Word = '{target_word}'")

        while attempts < game.max_attempts:
            guess = agent.get_action(state)
            feedback = game.get_feedback(guess)

            # Print each guess and feedback
            print(f"Attempt {attempts + 1}: Guess = '{guess}', Feedback = '{feedback}'")

            if guess == target_word:
                reward = 10  # Reward for correct guess
                agent.update_q_value(state, guess, reward)
                print("Correct guess! Ending episode.\n")
                break

            reward = -1  # Negative reward for incorrect guess
            agent.update_q_value(state, guess, reward)
            state = feedback
            attempts += 1

        attempts_over_episodes.append(attempts if guess == target_word else game.max_attempts)
        target_word = random.choice(word_list)  # Reset target word for next episode

    # Plotting the results
    plot_feedback_accuracy(attempts_over_episodes)
    plot_q_values_heatmap(agent.q_table)

if __name__ == "__main__":
    main()